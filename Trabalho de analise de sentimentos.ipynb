{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "duplicate-physics",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#######  importar as bibliotecas ##########  \n",
    "\n",
    "#pip install -U textblob\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "#!{sys.executable} \n",
    "#-m pip install contractions\n",
    "\n",
    "import re\n",
    "import collections\n",
    "import random\n",
    "import string\n",
    "import sklearn\n",
    "import contractions\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import nltk.stem as stem\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "import unicodedata\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "### classificadores ####\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB)\n",
    "from nltk.classify import NaiveBayesClassifier as nbc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from nltk.metrics import scores\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chemical-bahamas",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#importar a base de dados \n",
    "treino=pd.read_csv(\"/Users/Guilherme/Desktop/trabalho/train.csv\")\n",
    "teste=pd.read_csv(\"/Users/Guilherme/Desktop/trabalho/test.csv\")\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regional-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:ylabel='Treino'>, <AxesSubplot:ylabel='Teste'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Gráficos distribuição sentimentos nos conjuntos de treino e teste\n",
    "counts_teste= [(teste[\"Sentiment\"]==\"POS\").sum(),(teste[\"Sentiment\"]==\"NEG\").sum()]\n",
    "counts_treino= [(treino[\"Sentiment\"]==\"POS\").sum(),(treino[\"Sentiment\"]==\"NEG\").sum()]\n",
    "data = {'Treino': [(treino[\"Sentiment\"]==\"POS\").sum(), (treino[\"Sentiment\"]==\"NEG\").sum()]\n",
    "        ,'Teste': [(teste[\"Sentiment\"]==\"POS\").sum(), (teste[\"Sentiment\"]==\"NEG\").sum()]\n",
    "        ,\"Sentiment\":[\"pos\",\"neg\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df.groupby(['Sentiment']).sum().plot(kind='pie', subplots=True, shadow = True,startangle=90,figsize=(15,10),autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-institute",
   "metadata": {},
   "source": [
    "<h3>Funções</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dried-breath",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Baseado nos slides da disciplina de Text Mining\n",
    "\n",
    "classifiers = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\"BernoulliNB\": BernoulliNB()\n",
    "}\n",
    "\n",
    "# Função para classificar o dataset das features --> NLTK\n",
    "###################################################################\n",
    "\n",
    "def train_and_evaluate1(train_set, test_set):\n",
    "    for name, sklearn_classifier in classifiers.items():\n",
    "        classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "        classifier.train(train_set)\n",
    "        accuracy = nltk.classify.accuracy(classifier, train_set)\n",
    "        accuracy1 = nltk.classify.accuracy(classifier, test_set)\n",
    "        print(\"treino\",F\"{accuracy:.2%} - {name}\")\n",
    "        print(\"teste\",F\"{accuracy1:.2%} - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-cycling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseado em: https://realpython.com/python-nltk-sentiment-analysis/\n",
    "\n",
    "### Otimização dos parâmetros\n",
    "###################################################################\n",
    "\n",
    "tuned_parametersSVC = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4,'scale'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['poly'], 'gamma': [1e-3, 1e-4,'scale'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parametersMLP = [{'max_iter':[500],'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "                     'learning_rate_init':[0.001,0.005,0.01,0.1]}]\n",
    "\n",
    "tuned_parametersLOG= [{'solver':['liblinear'],'C': [1, 10, 100, 1000],'max_iter':[100,500,1000]}]\n",
    "\n",
    "tuned_parametersRANDTREE=[{'n_estimators':[100,500,1000],'max_depth':[1,2,3,4],'max_features':[\"auto\", \"sqrt\", \"log2\"]}]\n",
    "\n",
    "\n",
    "classifiers2 = {\"C-Support Vector Classification\": GridSearchCV(SVC(), param_grid =tuned_parametersSVC,refit=True,cv=10),\n",
    "               \"MLPClassifier\":GridSearchCV(MLPClassifier(), param_grid =tuned_parametersMLP,refit=True,cv=10),\n",
    "               \"LogisticRegression\":GridSearchCV(LogisticRegression(),param_grid =tuned_parametersLOG,refit=True,cv=10),\n",
    "               \"RandomForestClassifier\":GridSearchCV(RandomForestClassifier(),param_grid =tuned_parametersRANDTREE,refit=True,cv=10),\n",
    "               }\n",
    "\n",
    "\n",
    "\n",
    "# Função para classificação dos modelos finais\n",
    "###################################################################\n",
    "def train_and_evaluate2(classifiers2):\n",
    "    for name, sklearn_classifier in classifiers2.items():\n",
    "        classifier = sklearn_classifier\n",
    "        classifier.fit(treino_X,treino_list_sent)\n",
    "        print(classifier.best_params_)\n",
    "        classifier.best_score_\n",
    "        params=classifier.cv_results_['params']\n",
    "        means = classifier.cv_results_['mean_test_score']\n",
    "        stds = classifier.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "        pred=classifier.predict(treino_X)\n",
    "        pred2=classifier.predict(teste_X)\n",
    "        print(\"Mislabeled points: {} out of {} - {}\".format((treino_list_sent!=pred).sum(), treino_X.shape[0], name))\n",
    "        print(\"Mislabeled points: {} out of {} - {}\".format((teste_list_sent!=pred2).sum(), teste_X.shape[0], name))\n",
    "        print(\"Accuracy: {} - {}\".format(metrics.accuracy_score(treino_list_sent, pred), name))\n",
    "        print(\"Accuracy: {} - {}\".format(metrics.accuracy_score(teste_list_sent, pred2), name))\n",
    "        #print(\"Precision:{} - {}\".format(metrics.precision_score(treino_list_sent, pred, average=\"macro\"),name))\n",
    "        #print(\"Precision:{} - {}\".format(metrics.precision_score(teste_list_sent, pred2, average=\"macro\"),name))\n",
    "        #print(\"Recall: {} - {}\".format(metrics.recall_score(treino_list_sent, pred, average=\"macro\"),name))\n",
    "        #print(\"Recall: {} - {}\".format(metrics.recall_score(teste_list_sent, pred2, average=\"macro\"),name))\n",
    "        #print(\"F1-measure: {} - {}\".format(metrics.f1_score(treino_list_sent, pred, average=\"macro\"),name))\n",
    "        #print(\"F1-measure: {} - {}\".format(metrics.f1_score(teste_list_sent, pred2, average=\"macro\"),name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overall-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers1 = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(solver='liblinear'),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"C-Support Vector Classification\": SVC(),\n",
    "}\n",
    "\n",
    "\n",
    "# Função para classificar o pré-processamento, skillit_learn\n",
    "def train_and_evaluate3(classifiers1):\n",
    "    for name, sklearn_classifier in classifiers1.items():\n",
    "        classifier = sklearn_classifier\n",
    "        classifier.fit(treino_X,treino_list_sent)\n",
    "        pred=classifier.predict(treino_X)\n",
    "        pred2=classifier.predict(teste_X)\n",
    "        print(\"Mislabeled points: {} out of {} - {}\".format((treino_list_sent!=pred).sum(), treino_X.shape[0], name))\n",
    "        print(\"Mislabeled points: {} out of {} - {}\".format((teste_list_sent!=pred2).sum(), teste_X.shape[0], name))\n",
    "        print(\"Accuracy: {} - {}\".format(metrics.accuracy_score(treino_list_sent, pred), name))\n",
    "        print(\"Accuracy: {} - {}\".format(metrics.accuracy_score(teste_list_sent, pred2), name))\n",
    "        #print(\"Precision:{} - {}\".format(metrics.precision_score(treino_list_sent, pred, average=\"macro\"),name))\n",
    "        #print(\"Precision:{} - {}\".format(metrics.precision_score(teste_list_sent, pred2, average=\"macro\"),name))\n",
    "        #print(\"Recall: {} - {}\".format(metrics.recall_score(treino_list_sent, pred, average=\"macro\"),name))\n",
    "        #print(\"Recall: {} - {}\".format(metrics.recall_score(teste_list_sent, pred2, average=\"macro\"),name))\n",
    "        #print(\"F1-measure: {} - {}\".format(metrics.f1_score(treino_list_sent, pred, average=\"macro\"),name))\n",
    "        #print(\"F1-measure: {} - {}\".format(metrics.f1_score(teste_list_sent, pred2, average=\"macro\"),name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metric-mississippi",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseado em: https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html\n",
    "\n",
    "# Função para fazer merge de 2 listas que ficam no formato de tuplo\n",
    "def merge(list1, list2):\n",
    "      \n",
    "    merged_list = tuple(zip(list1, list2)) \n",
    "    return merged_list\n",
    "\n",
    "\n",
    "##### Função para a eliminação dos acentos\n",
    "############################################\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "##### Função para a eliminação dos carateres especiais e digitos\n",
    "###################################################################\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "##### Função para o Stemming\n",
    "############################################\n",
    "\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.snowball.SnowballStemmer(\"english\")\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "##### Função para o Lemming\n",
    "############################################\n",
    "def simple_Lemmatizer(text):\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = ' '.join([lem.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "##### Função para remoção das stopwords\n",
    "############################################\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "def remove_stopwords(text, is_lower_case=True):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "##### Função para seleção das features\n",
    "############################################\n",
    "def docs2features(docs, selected_features):\n",
    "    features = []\n",
    "    for doc_feature_counts, tag in docs:\n",
    "        features.append(({f:doc_feature_counts[f] for f in selected_features}, tag))\n",
    "    return features\n",
    "\n",
    "\n",
    "#### Função para testar a accuracy da aplicação do léxico de sentimentos\n",
    "########################################################################\n",
    "def accuracy_lexico(review):\n",
    "    classificacao=[] ## Tuplo comentário-sentimento\n",
    "    for x in review:\n",
    "        if x>=0:\n",
    "            classificacao.append(\"POS\")\n",
    "        if x<0:\n",
    "            classificacao.append(\"NEG\")     \n",
    "    classificacao #classificacao - lista com a classificação de sentimento\n",
    "    # Driver code\n",
    "    classificacao_sent=merge(teste_list,classificacao) #classificacao_sent # tuplo com frase e sentimento\n",
    "    \n",
    "    i=0\n",
    "    total_acertos=0\n",
    "    for x in teste_list_sent:\n",
    "        if x == classificacao[i]:\n",
    "            total_acertos=total_acertos+1\n",
    "        i=i+1\n",
    "    print(\"Total de comentários -->\", len(teste_list))\n",
    "    print(\"Total de sentimentos bem identificados-->\", total_acertos)\n",
    "    print(\"Accuracy -->\", total_acertos/len(teste_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-wallace",
   "metadata": {},
   "source": [
    "<h1> I.2. PREPARAÇÃO DOS DADOS E CRIAÇÃO DE UMA BASELINE </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-index",
   "metadata": {},
   "source": [
    "<h2> Conversão dos dados </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defensive-ground",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Conjunto Treino: Conversão das colunas text e sentiment do dataset para lista\n",
    "treino_list=treino[\"Text\"].to_list() # passagem dos comentários para lista\n",
    "treino_list_sent=treino[\"Sentiment\"].to_list() # passagem dos sentimentos/tag para lista\n",
    "#\n",
    "#treino_list # todos os comentários estão separados por vírgula, no formato string\n",
    "\n",
    "# Conjunto Teste: Conversão das colunas text e sentiment do dataset para lista\n",
    "teste_list=teste[\"Text\"].to_list()\n",
    "teste_list_sent=teste[\"Sentiment\"].to_list()\n",
    "#treino_list_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-malpractice",
   "metadata": {},
   "source": [
    "<h2> Criação da Baseline </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-mandate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 37 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 51 out of 400 - MultinomialNB\n",
      "Accuracy: 0.976875 - MultinomialNB\n",
      "Accuracy: 0.8725 - MultinomialNB\n",
      "Mislabeled points: 25 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 44 out of 400 - BernoulliNB\n",
      "Accuracy: 0.984375 - BernoulliNB\n",
      "Accuracy: 0.89 - BernoulliNB\n"
     ]
    }
   ],
   "source": [
    "### Baseado nos slides da disciplina de Text Mining\n",
    "\n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list) # Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list) # Transform documents to document-term matrix.\n",
    "\n",
    "train_and_evaluate3(classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-hollow",
   "metadata": {},
   "source": [
    "<h1> 1.3 APLICAÇÃO DE UM LÉXICO DE SENTIMENTOS </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removable-costume",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Baseado nos slides da disciplina de Text Mining\n",
    "\n",
    "# Importar o léxico - leitura linha a linha\n",
    "import csv\n",
    "lexicon={}\n",
    "with open(\"/Users/Guilherme/Desktop/trabalho/NCR-lexicon.csv\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=\",\" ) #assigns an index to each item in an iterable object that can be used to reference the item later\n",
    "    for i, d in enumerate(reader):\n",
    "        lexicon[d[\"English\"]]=int(d[\"Positive\"]) - int(d[\"Negative\"])\n",
    "#lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-dependence",
   "metadata": {},
   "source": [
    "<h2>a) Aplicação do léxico de sentimentos s/ tratamento da negação</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-gross",
   "metadata": {},
   "source": [
    "<h3> A.1 - Cálculo da Accuracy sem o tratamento da negação </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "computational-bolivia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de comentários --> 400\n",
      "Total de sentimentos bem identificados--> 200\n",
      "Accuracy --> 0.5\n"
     ]
    }
   ],
   "source": [
    "### Ciclo que retorna os valores de lexicon, em que cada frase é uma lista\n",
    "teste_list_tok2=[]\n",
    "for x in teste_list:\n",
    "    teste_list_tok1=word_tokenize(x.lower())\n",
    "    teste_list_tok2.append(teste_list_tok1)\n",
    "\n",
    "# CICLO PARA APLICAÇÃO DO LEXICON\n",
    "contador_pos=0\n",
    "contador_neg=0\n",
    "review=[]\n",
    "contador_total=0\n",
    "comentario=teste_list_tok2\n",
    "for x in range(len(comentario)):\n",
    "        for y in range(len(comentario[x])):\n",
    "            if comentario[x][y] in lexicon:\n",
    "                a=lexicon[comentario[x][y]]\n",
    "                #print(a)\n",
    "                contador_pos=0\n",
    "                contador_neg=0\n",
    "                contador_total=0\n",
    "                if a >=0:\n",
    "                    contador_pos=contador_pos+1\n",
    "                if a <0:\n",
    "                    contador_neg=contador_neg+1  \n",
    "            contador_total=contador_pos-contador_neg\n",
    "        if contador_total >=0:\n",
    "            contador_total=1\n",
    "        else:\n",
    "            contador_total=-1\n",
    "        review.append(contador_total)\n",
    "\n",
    "#review # --> devolve uma lista com valores de -1 a 1\n",
    "\n",
    "#len(review) # 400 elementos\n",
    "\n",
    "accuracy_lexico(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-shelf",
   "metadata": {},
   "source": [
    "<h2>b) Aplicação do léxico de sentimentos c/ tratamento da negação</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-possession",
   "metadata": {},
   "source": [
    "<h2>Tratamento da Negação </h2>\n",
    "<h3> Alteração das contrações n't para not </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coordinate-nomination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Baseado em: https://www.geeksforgeeks.org/nlp-expand-contractions-in-text-processing/\n",
    "\n",
    "### Alteração das contrações n't para not\n",
    "expanded_words=[]\n",
    "expanded_words_coment=[]\n",
    "for x in teste_list:\n",
    "    for y in x.split():  \n",
    "        expanded_words.append(contractions.fix(y))\n",
    "    expanded_words_coment.append(' '.join(list(expanded_words))) # Devolve uma lista onde os comentários estão em string\n",
    "    expanded_words=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-croatia",
   "metadata": {},
   "source": [
    "<h3> A.2 - Aplicação do léxico de sentimentos c/ tratamento da negação</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cooperative-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de comentários --> 400\n",
      "Total de sentimentos bem identificados--> 208\n",
      "Accuracy --> 0.52\n"
     ]
    }
   ],
   "source": [
    "### Ciclo que retorna os valores de lexicon, em que cada comentário é uma lista\n",
    "teste_list_tok4=[]\n",
    "for x in expanded_words_coment:\n",
    "    teste_list_tok3=word_tokenize(x.lower())\n",
    "    teste_list_tok4.append(teste_list_tok3)\n",
    "\n",
    "# CICLO PARA O LEXICON COM TRATAMENTO DA NEGAÇÃO\n",
    "### Se a palavra not for detetada, a palavra seguinte passa a negativa (-1) ou positiva (1)\n",
    "contador_pos=0\n",
    "contador_neg=0\n",
    "review3=[]\n",
    "contador_total=0\n",
    "comentario=teste_list_tok4\n",
    "for x in range(len(comentario)):\n",
    "    contador_not=0\n",
    "    for y in range(len(comentario[x])):\n",
    "        if comentario[x][y]==\"not\":\n",
    "            contador_not=1\n",
    "        if comentario[x][y] in lexicon:\n",
    "            a=lexicon[comentario[x][y]]\n",
    "            #print(a)\n",
    "            contador_pos=0\n",
    "            contador_neg=0\n",
    "            contador_total=0\n",
    "            if contador_not==1 and (a>0 or a<0):\n",
    "                contador_pos=-1\n",
    "                contador_neg=1\n",
    "                contador_not=0\n",
    "            if a >=0:\n",
    "                contador_pos=contador_pos+1\n",
    "            if a <0:\n",
    "                contador_neg=contador_neg+1  \n",
    "        contador_total=contador_pos-contador_neg\n",
    "    if contador_total >=0:\n",
    "        contador_total=1\n",
    "    else:\n",
    "        contador_total=-1\n",
    "    review3.append(contador_total)  # --> devolve uma lista com valores de -1 a 1\n",
    "\n",
    "#review3\n",
    "\n",
    "#len(review3) 400 listas\n",
    "\n",
    "accuracy_lexico(review3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-firewall",
   "metadata": {},
   "source": [
    "<h3> A.3 - Aplicação do léxico de sentimentos c/ tratamento da negação +\n",
    "remoção das stopwords, carateres especiais, acentos e digitos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designing-causing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de comentários --> 400\n",
      "Total de sentimentos bem identificados--> 208\n",
      "Accuracy --> 0.52\n"
     ]
    }
   ],
   "source": [
    "teste_lex_spe=[]\n",
    "teste_lex_clean=[]\n",
    "teste_lex_stop=[]\n",
    "for x in expanded_words_coment:\n",
    "    teste_lex_spe.append(remove_special_characters(x,remove_digits=True))\n",
    "    for y in teste_lex_spe:\n",
    "        teste_lex_clean.append(remove_accented_chars(y))\n",
    "        for z in teste_lex_clean:\n",
    "            teste_lex_stop.append(remove_stopwords(z.lower()))\n",
    "        teste_lex_clean=[]\n",
    "    teste_lex_spe=[]\n",
    "\n",
    "\n",
    "# CICLO PARA O LEXICON COM TRATAMENTO DA NEGAÇÃO\n",
    "### Se a palavra not for detetada, a palavra seguinte passa a negativa (-1) ou positiva (1)\n",
    "teste_list_tok6=[]\n",
    "for x in teste_lex_stop:\n",
    "    teste_list_tok5=word_tokenize(x)\n",
    "    teste_list_tok6.append(teste_list_tok5)\n",
    "\n",
    "\n",
    "contador_pos=0\n",
    "contador_neg=0\n",
    "review4=[]\n",
    "contador_total=0\n",
    "comentario=teste_list_tok6\n",
    "for x in range(len(comentario)):\n",
    "    contador_not=0\n",
    "    for y in range(len(comentario[x])):\n",
    "        if comentario[x][y]==\"not\":\n",
    "            contador_not=1\n",
    "        if comentario[x][y] in lexicon:\n",
    "            a=lexicon[comentario[x][y]]\n",
    "            #print(a)\n",
    "            contador_pos=0\n",
    "            contador_neg=0\n",
    "            contador_total=0\n",
    "            if contador_not==1 and (a>0 or a<0):\n",
    "                contador_pos=-1\n",
    "                contador_neg=1\n",
    "                contador_not=0\n",
    "            if a >=0:\n",
    "                contador_pos=contador_pos+1\n",
    "            if a <0:\n",
    "                contador_neg=contador_neg+1  \n",
    "        contador_total=contador_pos-contador_neg\n",
    "    if contador_total >=0:\n",
    "        contador_total=1\n",
    "    else:\n",
    "        contador_total=-1\n",
    "    review4.append(contador_total)   # --> devolve uma lista com valores de -1 a 1\n",
    "\n",
    "#review4\n",
    "\n",
    "#len(review4) #400 listas\n",
    "accuracy_lexico(review4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-brass",
   "metadata": {},
   "source": [
    "<h1> PART II Aprendizagem Automática </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-arbor",
   "metadata": {},
   "source": [
    "<h2> PRÉ-PROCESSAMENTO </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-intent",
   "metadata": {},
   "source": [
    "<h3> <b> B.1 - Stemming</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electoral-killing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseado em: https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html\n",
    "\n",
    "# Aplicação do Stemming ao conjunto de treino\n",
    "treino_list_stem=[]\n",
    "for x in treino_list:\n",
    "    treino_list_stem.append(simple_stemmer(x)) # Devolve uma lista onde os comentários estão em string\n",
    "    \n",
    "# Aplicação do Stemming ao conjunto de teste\n",
    "teste_list_stem=[]\n",
    "for x in teste_list:\n",
    "    teste_list_stem.append(simple_stemmer(x)) # Devolve uma lista onde os comentários estão em string\n",
    "\n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_stem)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_stem) # Transform documents to document-term matrix.\n",
    "\n",
    "#treino_X.shape #(1600, 20889)\n",
    "#teste_X.shape #(400, 20889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "substantial-jimmy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 30 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 49 out of 400 - BernoulliNB\n",
      "Accuracy: 0.98125 - BernoulliNB\n",
      "Accuracy: 0.8775 - BernoulliNB\n",
      "Mislabeled points: 41 out of 1600 - ComplementNB\n",
      "Mislabeled points: 51 out of 400 - ComplementNB\n",
      "Accuracy: 0.974375 - ComplementNB\n",
      "Accuracy: 0.8725 - ComplementNB\n",
      "Mislabeled points: 39 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 51 out of 400 - MultinomialNB\n",
      "Accuracy: 0.975625 - MultinomialNB\n",
      "Accuracy: 0.8725 - MultinomialNB\n",
      "Mislabeled points: 382 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 150 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.76125 - KNeighborsClassifier\n",
      "Accuracy: 0.625 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 66 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.835 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 48 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.88 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 58 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.855 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 61 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.8475 - MLPClassifier\n",
      "Mislabeled points: 104 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 56 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.935 - AdaBoostClassifier\n",
      "Accuracy: 0.86 - AdaBoostClassifier\n",
      "Mislabeled points: 141 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 77 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.911875 - C-Support Vector Classification\n",
      "Accuracy: 0.8075 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-enterprise",
   "metadata": {},
   "source": [
    "<h3>B.2 - Eliminação dos carateres especiais, acentos e digitos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "otherwise-adult",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseado em: https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html\n",
    "\n",
    "# Aplicação da eliminação dos carateres especiais, acentos e digitos ao conjunto de treino\n",
    "treino_list_spe=[]\n",
    "treino_list_clean=[]\n",
    "for x in treino_list:\n",
    "    treino_list_spe.append(remove_special_characters(x,remove_digits=True))\n",
    "    for y in treino_list_spe:\n",
    "        treino_list_clean.append(remove_accented_chars(y))   # Devolve uma lista onde os comentários estão em string\n",
    "    treino_list_spe=[]\n",
    "\n",
    "# Aplicação da eliminação dos carateres especiais, acentos e digitos ao conjunto de teste\n",
    "teste_list_spe=[]\n",
    "teste_list_clean=[]\n",
    "\n",
    "for x in teste_list:\n",
    "    teste_list_spe.append(remove_special_characters(x,remove_digits=True))\n",
    "    for y in teste_list_spe:\n",
    "        teste_list_clean.append(remove_accented_chars(y))  # Devolve uma lista onde os comentários estão em string\n",
    "    teste_list_spe=[]\n",
    "    \n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_clean)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_clean) # Transform documents to document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "expired-meter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 15 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 43 out of 400 - BernoulliNB\n",
      "Accuracy: 0.990625 - BernoulliNB\n",
      "Accuracy: 0.8925 - BernoulliNB\n",
      "Mislabeled points: 24 out of 1600 - ComplementNB\n",
      "Mislabeled points: 54 out of 400 - ComplementNB\n",
      "Accuracy: 0.985 - ComplementNB\n",
      "Accuracy: 0.865 - ComplementNB\n",
      "Mislabeled points: 24 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 54 out of 400 - MultinomialNB\n",
      "Accuracy: 0.985 - MultinomialNB\n",
      "Accuracy: 0.865 - MultinomialNB\n",
      "Mislabeled points: 392 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 159 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.755 - KNeighborsClassifier\n",
      "Accuracy: 0.6025 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 45 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.8875 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 54 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.865 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 52 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.87 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 56 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.86 - MLPClassifier\n",
      "Mislabeled points: 143 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 58 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.910625 - AdaBoostClassifier\n",
      "Accuracy: 0.855 - AdaBoostClassifier\n",
      "Mislabeled points: 139 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 73 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.913125 - C-Support Vector Classification\n",
      "Accuracy: 0.8175 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-hammer",
   "metadata": {},
   "source": [
    "<h3>B.3 -  Lematização </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "occupied-meter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseado em: https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html\n",
    "\n",
    "# Aplicação da Lematização no conjunto de treino\n",
    "treino_list_lem=[]\n",
    "for x in treino_list:\n",
    "    treino_list_lem.append(simple_Lemmatizer(x))\n",
    "    \n",
    "# Aplicação da Lematização no conjunto de teste\n",
    "teste_list_lem=[]\n",
    "for x in teste_list:\n",
    "    teste_list_lem.append(simple_Lemmatizer(x))\n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_lem)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_lem) # Transform documents to document-term matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "moving-socket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 28 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 46 out of 400 - BernoulliNB\n",
      "Accuracy: 0.9825 - BernoulliNB\n",
      "Accuracy: 0.885 - BernoulliNB\n",
      "Mislabeled points: 37 out of 1600 - ComplementNB\n",
      "Mislabeled points: 49 out of 400 - ComplementNB\n",
      "Accuracy: 0.976875 - ComplementNB\n",
      "Accuracy: 0.8775 - ComplementNB\n",
      "Mislabeled points: 37 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 49 out of 400 - MultinomialNB\n",
      "Accuracy: 0.976875 - MultinomialNB\n",
      "Accuracy: 0.8775 - MultinomialNB\n",
      "Mislabeled points: 386 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 163 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.75875 - KNeighborsClassifier\n",
      "Accuracy: 0.5925 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 49 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.8775 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 52 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.87 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 51 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.8725 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 51 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.8725 - MLPClassifier\n",
      "Mislabeled points: 141 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 49 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.911875 - AdaBoostClassifier\n",
      "Accuracy: 0.8775 - AdaBoostClassifier\n",
      "Mislabeled points: 137 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 78 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.914375 - C-Support Vector Classification\n",
      "Accuracy: 0.805 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-skill",
   "metadata": {},
   "source": [
    "<h3>B.4 - Stopwords </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cognitive-architecture",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Baseado nos slides da disciplina de Text Mining\n",
    "# Aplicação da remoção de stopwords ao conjunto de treino\n",
    "treino_list_stop=[]\n",
    "for x in treino_list:\n",
    "    treino_list_stop.append(remove_stopwords(x))\n",
    "    \n",
    "# Aplicação da remoção de stopwords ao conjunto de teste\n",
    "teste_list_stop=[]\n",
    "for x in teste_list:\n",
    "    teste_list_stop.append(remove_stopwords(x))\n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_stop)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_stop) # Transform documents to document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indirect-brake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 18 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 42 out of 400 - BernoulliNB\n",
      "Accuracy: 0.98875 - BernoulliNB\n",
      "Accuracy: 0.895 - BernoulliNB\n",
      "Mislabeled points: 27 out of 1600 - ComplementNB\n",
      "Mislabeled points: 54 out of 400 - ComplementNB\n",
      "Accuracy: 0.983125 - ComplementNB\n",
      "Accuracy: 0.865 - ComplementNB\n",
      "Mislabeled points: 26 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 54 out of 400 - MultinomialNB\n",
      "Accuracy: 0.98375 - MultinomialNB\n",
      "Accuracy: 0.865 - MultinomialNB\n",
      "Mislabeled points: 367 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 155 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.770625 - KNeighborsClassifier\n",
      "Accuracy: 0.6125 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 46 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.885 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 37 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.9075 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 45 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.8875 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 49 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.8775 - MLPClassifier\n",
      "Mislabeled points: 128 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 53 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.92 - AdaBoostClassifier\n",
      "Accuracy: 0.8675 - AdaBoostClassifier\n",
      "Mislabeled points: 15 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 55 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.990625 - C-Support Vector Classification\n",
      "Accuracy: 0.8625 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-bailey",
   "metadata": {},
   "source": [
    "<h3>B.5 - Número de features </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "metallic-bacon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Baseado nos slides da disciplina de Text Mining\n",
    "\n",
    "#### Conjunto Treino\n",
    "treino_tuplo=treino[[\"Text\",\"Sentiment\"]]\n",
    "treino_tuplo= treino_tuplo.to_records(index=False)\n",
    "treino_tuplo=list(treino_tuplo)\n",
    "\n",
    "### Criação das features para o conjunto de treino\n",
    "stopw = stopwords.words('english')\n",
    "docrep_treino=[]\n",
    "for text,tag in treino_tuplo:\n",
    "    features = FreqDist(w for w in word_tokenize(text) \n",
    "        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep_treino.append((features, tag))\n",
    "    \n",
    "\n",
    "#### Conjunto Teste\n",
    "teste_tuplo=teste[[\"Text\",\"Sentiment\"]]\n",
    "teste_tuplo=teste_tuplo.to_records(index=False)\n",
    "teste_tuplo=list(teste_tuplo)\n",
    "\n",
    "  \n",
    "### Criação das features para o conjunto de teste\n",
    "stopw = stopwords.words('english')\n",
    "docrep_teste=[]\n",
    "for text,tag in teste_tuplo:\n",
    "    features = FreqDist(w for w in word_tokenize(text)\n",
    "        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep_teste.append((features, tag))\n",
    "    \n",
    "# Identificação das features mais importantes do conjunto de treino\n",
    "feature_counts1=FreqDist()\n",
    "for doc_feature_counts, _ in docrep_treino:\n",
    "    feature_counts1 += doc_feature_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-integration",
   "metadata": {},
   "source": [
    "<h4> Selecção do numero ideal de features </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "italic-incentive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino 90.12% - MultinomialNB\n",
      "teste 86.50% - MultinomialNB\n",
      "treino 89.25% - BernoulliNB\n",
      "teste 87.00% - BernoulliNB\n",
      "treino 95.31% - MultinomialNB\n",
      "teste 87.75% - MultinomialNB\n",
      "treino 96.06% - BernoulliNB\n",
      "teste 88.50% - BernoulliNB\n",
      "treino 97.50% - MultinomialNB\n",
      "teste 87.25% - MultinomialNB\n",
      "treino 98.31% - BernoulliNB\n",
      "teste 90.00% - BernoulliNB\n",
      "treino 98.12% - MultinomialNB\n",
      "teste 86.00% - MultinomialNB\n",
      "treino 99.06% - BernoulliNB\n",
      "teste 89.50% - BernoulliNB\n",
      "treino 98.25% - MultinomialNB\n",
      "teste 86.50% - MultinomialNB\n",
      "treino 99.06% - BernoulliNB\n",
      "teste 89.00% - BernoulliNB\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# Seleção das 1000 features mais importantes do conjunto de treino e teste\n",
    "###############################################################\n",
    "selected_features1=[f for f,ntimes in feature_counts1.most_common(1000)]\n",
    "\n",
    "treino_set = docs2features(docrep_treino, selected_features1)\n",
    "teste_set = docs2features(docrep_teste, selected_features1)\n",
    "\n",
    "classifier = train_and_evaluate1(treino_set, teste_set) #0.835\n",
    "\n",
    "###############################################################\n",
    "# Seleção das 5000 features mais importantes do conjunto de treino e teste\n",
    "###############################################################\n",
    "selected_features2=[f for f,ntimes in feature_counts1.most_common(5000)]\n",
    "\n",
    "treino_set2 = docs2features(docrep_treino, selected_features2)\n",
    "teste_set2 = docs2features(docrep_teste, selected_features2)\n",
    "\n",
    "classifier2 = train_and_evaluate1(treino_set2, teste_set2) #0.863\n",
    "\n",
    "###############################################################\n",
    "# Seleção das 10000 features mais importantes do conjunto de treino e teste\n",
    "###############################################################\n",
    "selected_features3=[f for f,ntimes in feature_counts1.most_common(10000)]\n",
    "\n",
    "treino_set3 = docs2features(docrep_treino, selected_features3)\n",
    "teste_set3 = docs2features(docrep_teste, selected_features3)\n",
    "\n",
    "classifier3 = train_and_evaluate1(treino_set3, teste_set3) #0.875\n",
    "\n",
    "###############################################################\n",
    "# Seleção das 15000 features mais importantes do conjunto de treino e teste\n",
    "###############################################################\n",
    "selected_features4=[f for f,ntimes in feature_counts1.most_common(15000)]\n",
    "\n",
    "treino_set4 = docs2features(docrep_treino, selected_features4)\n",
    "teste_set4 = docs2features(docrep_teste, selected_features4)\n",
    "\n",
    "classifier4 = train_and_evaluate1(treino_set4, teste_set4) #0.877\n",
    "\n",
    "###############################################################\n",
    "# Seleção das 20000 features mais importantes do conjunto de treino e teste\n",
    "###############################################################\n",
    "selected_features5=[f for f,ntimes in feature_counts1.most_common(20000)]\n",
    "\n",
    "treino_set5 = docs2features(docrep_treino, selected_features5)\n",
    "teste_set5 = docs2features(docrep_teste, selected_features5)\n",
    "\n",
    "classifier5 = train_and_evaluate1(treino_set5, teste_set5) #0.870"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-russell",
   "metadata": {},
   "source": [
    "<h3>B.6 - POS  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cloudy-hostel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "###Conjunto de Treino\n",
    "docrep_pos_treino=[]\n",
    "for text,tag in treino_tuplo:\n",
    "    features = FreqDist(\"%s_%s\"%(w,p) for w,p in nltk.pos_tag(word_tokenize(text))\n",
    "        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep_pos_treino.append((features, tag)) # tuplos com a frequência de cada palavra em cada comentário\n",
    "\n",
    "feature_counts_treino=FreqDist()\n",
    "for doc_feature_counts_treino, t in docrep_pos_treino:\n",
    "    feature_counts_treino += doc_feature_counts_treino # 39164\n",
    "\n",
    "selected_features_treino=[f for f,freq in feature_counts_treino.most_common(1000)]\n",
    "\n",
    "###Conjunto de Teste   \n",
    "docrep_pos_teste=[]\n",
    "for text,tag in teste_tuplo:\n",
    "    features = FreqDist(\"%s_%s\"%(w,p) for w,p in nltk.pos_tag(word_tokenize(text))\n",
    "        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep_pos_teste.append((features, tag)) # tuplos com a frequência de cada palavra em cada comentário\n",
    "    \n",
    "treino_set_pos = docs2features(docrep_pos_treino, selected_features_treino)  # 1600 comentários\n",
    "teste_set_pos = docs2features(docrep_pos_teste, selected_features_treino) # 400 comentários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "executive-disclosure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino 89.12% - MultinomialNB\n",
      "teste 86.50% - MultinomialNB\n",
      "treino 89.38% - BernoulliNB\n",
      "teste 85.50% - BernoulliNB\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate1(treino_set_pos, teste_set_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-produce",
   "metadata": {},
   "source": [
    "<h1>  Cenários de combinação dos pré-processamentos </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-designation",
   "metadata": {},
   "source": [
    "<h2> C.1 - Texto sem pontuação, acentos e digitos e em minusculas</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pharmaceutical-diary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 15 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 43 out of 400 - BernoulliNB\n",
      "Accuracy: 0.990625 - BernoulliNB\n",
      "Accuracy: 0.8925 - BernoulliNB\n",
      "Mislabeled points: 24 out of 1600 - ComplementNB\n",
      "Mislabeled points: 54 out of 400 - ComplementNB\n",
      "Accuracy: 0.985 - ComplementNB\n",
      "Accuracy: 0.865 - ComplementNB\n",
      "Mislabeled points: 24 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 54 out of 400 - MultinomialNB\n",
      "Accuracy: 0.985 - MultinomialNB\n",
      "Accuracy: 0.865 - MultinomialNB\n",
      "Mislabeled points: 392 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 159 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.755 - KNeighborsClassifier\n",
      "Accuracy: 0.6025 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 43 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.8925 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 55 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.8625 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 52 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.87 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 60 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.85 - MLPClassifier\n",
      "Mislabeled points: 143 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 58 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.910625 - AdaBoostClassifier\n",
      "Accuracy: 0.855 - AdaBoostClassifier\n",
      "Mislabeled points: 139 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 73 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.913125 - C-Support Vector Classification\n",
      "Accuracy: 0.8175 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "# Aplicação da remoção de pontuação, acentos, digitos e minúsculas no conjunto de treino\n",
    "treino_list_sce_1=[]\n",
    "for x in treino_list_clean:\n",
    "    treino_list_sce_1.append(x.lower())\n",
    "    \n",
    "# Aplicação da remoção de pontuação, acentos, digitos e minúsculas no conjunto de teste\n",
    "teste_list_sce_1=[]\n",
    "for x in teste_list_clean:\n",
    "    teste_list_sce_1.append(x.lower())\n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_sce_1)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_sce_1) # Transform documents to document-term matrix.\n",
    "\n",
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-warrant",
   "metadata": {},
   "source": [
    " <h2> C.2 - Texto sem pontuação, acentos e digitos, em minusculas e com tratamento da negação   </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cognitive-holocaust",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 14 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 44 out of 400 - BernoulliNB\n",
      "Accuracy: 0.99125 - BernoulliNB\n",
      "Accuracy: 0.89 - BernoulliNB\n",
      "Mislabeled points: 26 out of 1600 - ComplementNB\n",
      "Mislabeled points: 57 out of 400 - ComplementNB\n",
      "Accuracy: 0.98375 - ComplementNB\n",
      "Accuracy: 0.8575 - ComplementNB\n",
      "Mislabeled points: 26 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 56 out of 400 - MultinomialNB\n",
      "Accuracy: 0.98375 - MultinomialNB\n",
      "Accuracy: 0.86 - MultinomialNB\n",
      "Mislabeled points: 374 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 153 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.76625 - KNeighborsClassifier\n",
      "Accuracy: 0.6175 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 46 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.885 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 51 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.8725 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 58 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.855 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 62 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.845 - MLPClassifier\n",
      "Mislabeled points: 137 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 63 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.914375 - AdaBoostClassifier\n",
      "Accuracy: 0.8425 - AdaBoostClassifier\n",
      "Mislabeled points: 146 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 77 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.90875 - C-Support Vector Classification\n",
      "Accuracy: 0.8075 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "# Aplicação da alteração das contrações n't para not no conjunto de treino\n",
    "expanded_words2=[]\n",
    "treino_list_sce_2=[]\n",
    "for x in treino_list_sce_1:\n",
    "    for y in x.split():  \n",
    "        expanded_words2.append(contractions.fix(y))\n",
    "    treino_list_sce_2.append(' '.join(list(expanded_words2)))\n",
    "    expanded_words2=[] \n",
    "    \n",
    "# Aplicação da alteração das contrações n't para not no conjunto de teste\n",
    "expanded_words2=[]\n",
    "teste_list_sce_2=[]\n",
    "for x in teste_list_sce_1:\n",
    "    for y in x.split():   \n",
    "        expanded_words2.append(contractions.fix(y))\n",
    "    teste_list_sce_2.append(' '.join(list(expanded_words2)))\n",
    "    expanded_words2=[]\n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_sce_2)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_sce_2) # Transform documents to document-term matrix.\n",
    "\n",
    "#Classificação\n",
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-aluminum",
   "metadata": {},
   "source": [
    " <h2> C.3 - cenário 2 + stopwords + stemming </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "minor-stewart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 16 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 48 out of 400 - BernoulliNB\n",
      "Accuracy: 0.99 - BernoulliNB\n",
      "Accuracy: 0.88 - BernoulliNB\n",
      "Mislabeled points: 21 out of 1600 - ComplementNB\n",
      "Mislabeled points: 57 out of 400 - ComplementNB\n",
      "Accuracy: 0.986875 - ComplementNB\n",
      "Accuracy: 0.8575 - ComplementNB\n",
      "Mislabeled points: 20 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 57 out of 400 - MultinomialNB\n",
      "Accuracy: 0.9875 - MultinomialNB\n",
      "Accuracy: 0.8575 - MultinomialNB\n",
      "Mislabeled points: 359 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 169 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.775625 - KNeighborsClassifier\n",
      "Accuracy: 0.5775 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 36 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.91 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 45 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.8875 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 46 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.885 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 60 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.85 - MLPClassifier\n",
      "Mislabeled points: 109 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 60 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.931875 - AdaBoostClassifier\n",
      "Accuracy: 0.85 - AdaBoostClassifier\n",
      "Mislabeled points: 19 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 64 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.988125 - C-Support Vector Classification\n",
      "Accuracy: 0.84 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "# Aplicação da eliminação das stopwords e de stemming no conjunto de treino\n",
    "treino_list_sce_3=[]\n",
    "for x in treino_list_sce_2:\n",
    "    treino_list_sce_3.append(simple_stemmer(remove_stopwords(x)))\n",
    "    \n",
    "# Aplicação da eliminação das stopwords e de stemming no conjunto de teste    \n",
    "teste_list_sce_3=[]\n",
    "for x in teste_list_sce_2:\n",
    "    teste_list_sce_3.append(simple_stemmer(remove_stopwords(x)))\n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_sce_3)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_sce_3) # Transform documents to document-term matrix.\n",
    "\n",
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-survival",
   "metadata": {},
   "source": [
    "<h2> C.4 - cenário 2 + stopwords+lemming </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "downtown-deficit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 11 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 44 out of 400 - BernoulliNB\n",
      "Accuracy: 0.993125 - BernoulliNB\n",
      "Accuracy: 0.89 - BernoulliNB\n",
      "Mislabeled points: 14 out of 1600 - ComplementNB\n",
      "Mislabeled points: 55 out of 400 - ComplementNB\n",
      "Accuracy: 0.99125 - ComplementNB\n",
      "Accuracy: 0.8625 - ComplementNB\n",
      "Mislabeled points: 13 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 54 out of 400 - MultinomialNB\n",
      "Accuracy: 0.991875 - MultinomialNB\n",
      "Accuracy: 0.865 - MultinomialNB\n",
      "Mislabeled points: 388 out of 1600 - KNeighborsClassifier\n",
      "Mislabeled points: 175 out of 400 - KNeighborsClassifier\n",
      "Accuracy: 0.7575 - KNeighborsClassifier\n",
      "Accuracy: 0.5625 - KNeighborsClassifier\n",
      "Mislabeled points: 0 out of 1600 - DecisionTreeClassifier\n",
      "Mislabeled points: 50 out of 400 - DecisionTreeClassifier\n",
      "Accuracy: 1.0 - DecisionTreeClassifier\n",
      "Accuracy: 0.875 - DecisionTreeClassifier\n",
      "Mislabeled points: 0 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 50 out of 400 - RandomForestClassifier\n",
      "Accuracy: 1.0 - RandomForestClassifier\n",
      "Accuracy: 0.875 - RandomForestClassifier\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 48 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.88 - LogisticRegression\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 49 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.8775 - MLPClassifier\n",
      "Mislabeled points: 139 out of 1600 - AdaBoostClassifier\n",
      "Mislabeled points: 56 out of 400 - AdaBoostClassifier\n",
      "Accuracy: 0.913125 - AdaBoostClassifier\n",
      "Accuracy: 0.86 - AdaBoostClassifier\n",
      "Mislabeled points: 23 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 63 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 0.985625 - C-Support Vector Classification\n",
      "Accuracy: 0.8425 - C-Support Vector Classification\n"
     ]
    }
   ],
   "source": [
    "# Aplicação da eliminação das stopwords e de lemming no conjunto de treino     \n",
    "treino_list_sce_4=[]\n",
    "for x in treino_list_sce_2:\n",
    "    treino_list_sce_4.append(simple_Lemmatizer(remove_stopwords(x)))\n",
    "    \n",
    "# Aplicação da eliminação das stopwords e de lemming no conjunto de teste        \n",
    "teste_list_sce_4=[]\n",
    "for x in teste_list_sce_2:\n",
    "    teste_list_sce_4.append(simple_Lemmatizer(remove_stopwords(x)))\n",
    "    \n",
    "# Vectorização\n",
    "vectorizer = CountVectorizer() #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_sce_4)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_sce_4) # Transform documents to document-term matrix.\n",
    "\n",
    "train_and_evaluate3(classifiers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-mobile",
   "metadata": {},
   "source": [
    "<h2> C.5 - cenário 3 + nºde features  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "labeled-barbados",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.841 (+/-0.059) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.615 (+/-0.053) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.850 (+/-0.056) for {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.874 (+/-0.064) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.854 (+/-0.063) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.871 (+/-0.061) for {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.875 (+/-0.060) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.872 (+/-0.063) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.871 (+/-0.059) for {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.875 (+/-0.060) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.871 (+/-0.062) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.871 (+/-0.059) for {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.514 (+/-0.021) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.506 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.593 (+/-0.052) for {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.549 (+/-0.049) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.506 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.713 (+/-0.056) for {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.630 (+/-0.059) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.507 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.761 (+/-0.069) for {'C': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.746 (+/-0.052) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.514 (+/-0.021) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.792 (+/-0.082) for {'C': 1000, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Mislabeled points: 0 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 52 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 1.0 - C-Support Vector Classification\n",
      "Accuracy: 0.87 - C-Support Vector Classification\n",
      "{'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.865 (+/-0.067) for {'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "0.859 (+/-0.061) for {'learning_rate': 'constant', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.868 (+/-0.047) for {'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "0.846 (+/-0.078) for {'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 500}\n",
      "0.860 (+/-0.059) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "0.858 (+/-0.052) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.865 (+/-0.050) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "0.826 (+/-0.043) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 500}\n",
      "0.865 (+/-0.060) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "0.869 (+/-0.056) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.858 (+/-0.063) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "0.843 (+/-0.056) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 500}\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 49 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.8775 - MLPClassifier\n",
      "{'C': 1, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.880 (+/-0.060) for {'C': 1, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.880 (+/-0.060) for {'C': 1, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.880 (+/-0.060) for {'C': 1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.874 (+/-0.060) for {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.874 (+/-0.060) for {'C': 10, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.874 (+/-0.060) for {'C': 10, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.874 (+/-0.062) for {'C': 100, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.874 (+/-0.062) for {'C': 100, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.874 (+/-0.062) for {'C': 100, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.864 (+/-0.059) for {'C': 1000, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.864 (+/-0.059) for {'C': 1000, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.864 (+/-0.059) for {'C': 1000, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 46 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.885 - LogisticRegression\n",
      "{'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.706 (+/-0.070) for {'max_depth': 1, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.750 (+/-0.050) for {'max_depth': 1, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.743 (+/-0.081) for {'max_depth': 1, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.732 (+/-0.053) for {'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.731 (+/-0.078) for {'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.746 (+/-0.073) for {'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.564 (+/-0.112) for {'max_depth': 1, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.526 (+/-0.025) for {'max_depth': 1, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.515 (+/-0.014) for {'max_depth': 1, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.799 (+/-0.053) for {'max_depth': 2, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.826 (+/-0.066) for {'max_depth': 2, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.830 (+/-0.048) for {'max_depth': 2, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.808 (+/-0.081) for {'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.823 (+/-0.073) for {'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.834 (+/-0.064) for {'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.600 (+/-0.062) for {'max_depth': 2, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.572 (+/-0.062) for {'max_depth': 2, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.589 (+/-0.058) for {'max_depth': 2, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.821 (+/-0.052) for {'max_depth': 3, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.857 (+/-0.060) for {'max_depth': 3, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.859 (+/-0.058) for {'max_depth': 3, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.823 (+/-0.089) for {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.845 (+/-0.059) for {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.856 (+/-0.044) for {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.671 (+/-0.111) for {'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.658 (+/-0.043) for {'max_depth': 3, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.639 (+/-0.086) for {'max_depth': 3, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.847 (+/-0.056) for {'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.866 (+/-0.054) for {'max_depth': 4, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.863 (+/-0.043) for {'max_depth': 4, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.849 (+/-0.059) for {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.862 (+/-0.039) for {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.867 (+/-0.055) for {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.680 (+/-0.033) for {'max_depth': 4, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.713 (+/-0.064) for {'max_depth': 4, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.710 (+/-0.071) for {'max_depth': 4, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "Mislabeled points: 125 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 54 out of 400 - RandomForestClassifier\n",
      "Accuracy: 0.921875 - RandomForestClassifier\n",
      "Accuracy: 0.865 - RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# Vectorização\n",
    "vectorizer = CountVectorizer(max_features=15000) #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_sce_3)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_sce_3) # Transform documents to document-term matrix.\n",
    "\n",
    "train_and_evaluate2(classifiers2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "varying-aging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 32 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 55 out of 400 - MultinomialNB\n",
      "Accuracy: 0.98 - MultinomialNB\n",
      "Accuracy: 0.8625 - MultinomialNB\n",
      "Mislabeled points: 22 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 47 out of 400 - BernoulliNB\n",
      "Accuracy: 0.98625 - BernoulliNB\n",
      "Accuracy: 0.8825 - BernoulliNB\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate3(classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-coordination",
   "metadata": {},
   "source": [
    "<h2> C.6 - cenário 4 + nºde features  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "interested-filename",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.817 (+/-0.064) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.597 (+/-0.061) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.837 (+/-0.073) for {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.869 (+/-0.053) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.830 (+/-0.066) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.862 (+/-0.057) for {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.872 (+/-0.055) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.869 (+/-0.046) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.861 (+/-0.057) for {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.872 (+/-0.055) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.865 (+/-0.051) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.861 (+/-0.057) for {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.512 (+/-0.017) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.506 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.583 (+/-0.052) for {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.544 (+/-0.046) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.506 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.696 (+/-0.058) for {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.610 (+/-0.047) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.507 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.741 (+/-0.066) for {'C': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.722 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.512 (+/-0.017) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.764 (+/-0.089) for {'C': 1000, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Mislabeled points: 0 out of 1600 - C-Support Vector Classification\n",
      "Mislabeled points: 50 out of 400 - C-Support Vector Classification\n",
      "Accuracy: 1.0 - C-Support Vector Classification\n",
      "Accuracy: 0.875 - C-Support Vector Classification\n",
      "{'learning_rate': 'invscaling', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.867 (+/-0.056) for {'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "0.867 (+/-0.049) for {'learning_rate': 'constant', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.861 (+/-0.051) for {'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "0.816 (+/-0.053) for {'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 500}\n",
      "0.869 (+/-0.059) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "0.875 (+/-0.050) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.869 (+/-0.050) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "0.836 (+/-0.061) for {'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 500}\n",
      "0.862 (+/-0.063) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "0.871 (+/-0.049) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 500}\n",
      "0.861 (+/-0.057) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "0.832 (+/-0.050) for {'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 500}\n",
      "Mislabeled points: 0 out of 1600 - MLPClassifier\n",
      "Mislabeled points: 47 out of 400 - MLPClassifier\n",
      "Accuracy: 1.0 - MLPClassifier\n",
      "Accuracy: 0.8825 - MLPClassifier\n",
      "{'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.869 (+/-0.050) for {'C': 1, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.869 (+/-0.050) for {'C': 1, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.869 (+/-0.050) for {'C': 1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.870 (+/-0.051) for {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.870 (+/-0.051) for {'C': 10, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.870 (+/-0.051) for {'C': 10, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.869 (+/-0.053) for {'C': 100, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.869 (+/-0.053) for {'C': 100, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.869 (+/-0.053) for {'C': 100, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.862 (+/-0.054) for {'C': 1000, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.862 (+/-0.054) for {'C': 1000, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "0.862 (+/-0.054) for {'C': 1000, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Mislabeled points: 0 out of 1600 - LogisticRegression\n",
      "Mislabeled points: 49 out of 400 - LogisticRegression\n",
      "Accuracy: 1.0 - LogisticRegression\n",
      "Accuracy: 0.8775 - LogisticRegression\n",
      "{'max_depth': 4, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.722 (+/-0.069) for {'max_depth': 1, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.729 (+/-0.056) for {'max_depth': 1, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.716 (+/-0.069) for {'max_depth': 1, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.713 (+/-0.087) for {'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.722 (+/-0.081) for {'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.733 (+/-0.082) for {'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.564 (+/-0.093) for {'max_depth': 1, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.518 (+/-0.026) for {'max_depth': 1, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.514 (+/-0.013) for {'max_depth': 1, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.764 (+/-0.072) for {'max_depth': 2, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.820 (+/-0.066) for {'max_depth': 2, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.820 (+/-0.063) for {'max_depth': 2, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.774 (+/-0.059) for {'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.802 (+/-0.059) for {'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.801 (+/-0.055) for {'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.608 (+/-0.078) for {'max_depth': 2, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.599 (+/-0.047) for {'max_depth': 2, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.566 (+/-0.036) for {'max_depth': 2, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.807 (+/-0.068) for {'max_depth': 3, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.831 (+/-0.082) for {'max_depth': 3, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.836 (+/-0.052) for {'max_depth': 3, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.795 (+/-0.057) for {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.840 (+/-0.063) for {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.846 (+/-0.071) for {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.656 (+/-0.076) for {'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.648 (+/-0.037) for {'max_depth': 3, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.646 (+/-0.071) for {'max_depth': 3, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.830 (+/-0.068) for {'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.855 (+/-0.072) for {'max_depth': 4, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.858 (+/-0.063) for {'max_depth': 4, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "0.821 (+/-0.067) for {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.854 (+/-0.062) for {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.853 (+/-0.059) for {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.691 (+/-0.063) for {'max_depth': 4, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.692 (+/-0.077) for {'max_depth': 4, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.694 (+/-0.084) for {'max_depth': 4, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "Mislabeled points: 135 out of 1600 - RandomForestClassifier\n",
      "Mislabeled points: 56 out of 400 - RandomForestClassifier\n",
      "Accuracy: 0.915625 - RandomForestClassifier\n",
      "Accuracy: 0.86 - RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# Vectorização\n",
    "vectorizer = CountVectorizer(max_features=15000) #The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. \n",
    "treino_X = vectorizer.fit_transform(treino_list_sce_4)# Learn the vocabulary dictionary and return document-term matrix.\n",
    "teste_X = vectorizer.transform(teste_list_sce_4) # Transform documents to document-term matrix.\n",
    "\n",
    "train_and_evaluate2(classifiers2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "annoying-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled points: 30 out of 1600 - MultinomialNB\n",
      "Mislabeled points: 51 out of 400 - MultinomialNB\n",
      "Accuracy: 0.98125 - MultinomialNB\n",
      "Accuracy: 0.8725 - MultinomialNB\n",
      "Mislabeled points: 22 out of 1600 - BernoulliNB\n",
      "Mislabeled points: 43 out of 400 - BernoulliNB\n",
      "Accuracy: 0.98625 - BernoulliNB\n",
      "Accuracy: 0.8925 - BernoulliNB\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate3(classifiers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
